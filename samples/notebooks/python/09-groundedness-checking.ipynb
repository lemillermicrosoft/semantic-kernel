{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5c76c5f",
   "metadata": {},
   "source": [
    "# Groundedness Checking Skills\n",
    "\n",
    "In this notebook we run a simple grounding pipeline, to see if a summary text has any ungrounded additions as compared to \n",
    "\n",
    "Let us first define our grounding text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23b26e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grounding_text = \"\"\"I am by birth a Genevese, and my family is one of the most distinguished of that republic.\n",
    "My ancestors had been for many years counsellors and syndics, and my father had filled several public situations\n",
    "with honour and reputation. He was respected by all who knew him for his integrity and indefatigable attention\n",
    "to public business. He passed his younger days perpetually occupied by the affairs of his country; a variety\n",
    "of circumstances had prevented his marrying early, nor was it until the decline of life that he became a husband\n",
    "and the father of a family.\n",
    "\n",
    "As the circumstances of his marriage illustrate his character, I cannot refrain from relating them. One of his\n",
    "most intimate friends was a merchant who, from a flourishing state, fell, through numerous mischances, into poverty.\n",
    "This man, whose name was Beaufort, was of a proud and unbending disposition and could not bear to live in poverty\n",
    "and oblivion in the same country where he had formerly been distinguished for his rank and magnificence. Having\n",
    "paid his debts, therefore, in the most honourable manner, he retreated with his daughter to the town of Lucerne,\n",
    "where he lived unknown and in wretchedness. My father loved Beaufort with the truest friendship and was deeply\n",
    "grieved by his retreat in these unfortunate circumstances. He bitterly deplored the false pride which led his friend\n",
    "to a conduct so little worthy of the affection that united them. He lost no time in endeavouring to seek him out,\n",
    "with the hope of persuading him to begin the world again through his credit and assistance.\n",
    "\n",
    "Beaufort had taken effectual measures to conceal himself, and it was ten months before my father discovered his\n",
    "abode. Overjoyed at this discovery, he hastened to the house, which was situated in a mean street near the Reuss.\n",
    "But when he entered, misery and despair alone welcomed him. Beaufort had saved but a very small sum of money from\n",
    "the wreck of his fortunes, but it was sufficient to provide him with sustenance for some months, and in the meantime\n",
    "he hoped to procure some respectable employment in a merchant's house. The interval was, consequently, spent in\n",
    "inaction; his grief only became more deep and rankling when he had leisure for reflection, and at length it took\n",
    "so fast hold of his mind that at the end of three months he lay on a bed of sickness, incapable of any exertion.\n",
    "\n",
    "His daughter attended him with the greatest tenderness, but she saw with despair that their little fund was\n",
    "rapidly decreasing and that there was no other prospect of support. But Caroline Beaufort possessed a mind of an\n",
    "uncommon mould, and her courage rose to support her in her adversity. She procured plain work; she plaited straw\n",
    "and by various means contrived to earn a pittance scarcely sufficient to support life.\n",
    "\n",
    "Several months passed in this manner. Her father grew worse; her time was more entirely occupied in attending him;\n",
    "her means of subsistence decreased; and in the tenth month her father died in her arms, leaving her an orphan and\n",
    "a beggar. This last blow overcame her, and she knelt by Beaufort's coffin weeping bitterly, when my father entered\n",
    "the chamber. He came like a protecting spirit to the poor girl, who committed herself to his care; and after the\n",
    "interment of his friend he conducted her to Geneva and placed her under the protection of a relation. Two years\n",
    "after this event Caroline became his wife.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bc7585",
   "metadata": {},
   "source": [
    "And the summary we're going to examine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a1ccbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_text = \"\"\"The narrator's father was a respected public figure in Geneva. He was friends with a wealthy\n",
    "merchant named Beaufort, who fell into poverty and retreated to Lucerne with his daughter. The narrator's father\n",
    "searched for ten months before finding Beaufort, who was sick and unable to work. Beaufort died after several\n",
    "months, leaving his daughter an orphan and a beggar. The narrator's father took her under his care and eventually\n",
    "married her two years later.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f4abc1",
   "metadata": {},
   "source": [
    "## Set up Semantic Kernel\n",
    "\n",
    "We prepare our kernel in the usual way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e13d3519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureTextCompletion, OpenAITextCompletion\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = True\n",
    "\n",
    "# Configure AI service used by the kernel\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"dv\", AzureTextCompletion(deployment, endpoint, api_key))\n",
    "else:\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"dv\", OpenAITextCompletion(\"text-davinci-003\", api_key, org_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c65f786",
   "metadata": {},
   "source": [
    "## Import the Skill\n",
    "\n",
    "We have to import the semantic and native skills in separate calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56ed7688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.core_skills.text_skill import TextSkill\n",
    "\n",
    "# note: using skills from the samples folder\n",
    "skills_directory = \"../../skills\"\n",
    "\n",
    "groundingSemanticFunctions = kernel.import_semantic_skill_from_directory(skills_directory, \"GroundingSkill\")\n",
    "summarize_skill = kernel.import_semantic_skill_from_directory(skills_directory, \"SummarizeSkill\")\n",
    "#writer_skill = kernel.import_semantic_skill_from_directory(skills_directory, \"WriterSkill\")\n",
    "#text_skill = kernel.import_skill(TextSkill(), \"TextSkill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "738eb0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_extraction = groundingSemanticFunctions[\"ExtractEntities\"]\n",
    "reference_check = groundingSemanticFunctions[\"ReferenceCheckEntities\"]\n",
    "entity_excision = groundingSemanticFunctions[\"ExciseEntities\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b48a4a5",
   "metadata": {},
   "source": [
    "## Preparing the context\n",
    "\n",
    "We now create the context in which will will operate. In the beginning, this just specifies the kind of entities we want to check for grounding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87d132ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = kernel.create_new_context()\n",
    "context[\"topic\"] = \"people and places\"\n",
    "context[\"example_entities\"] = \"names of people, familial relationships and towns\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2abe5e5",
   "metadata": {},
   "source": [
    "## Extracting the entities\n",
    "\n",
    "We're now ready to get the entities from the summary text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc482d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_result = entity_extraction(summary_text, context=context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a07b41",
   "metadata": {},
   "source": [
    "Examine the raw result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ed73fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Narrator's father\n",
      "- Geneva\n",
      "- Beaufort\n",
      "- Lucerne\n",
      "- Daughter of Beaufort\n",
      "- Narrator's father's care\n"
     ]
    }
   ],
   "source": [
    "print(extraction_result.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839b4a9a",
   "metadata": {},
   "source": [
    "## Reference cross check\n",
    "\n",
    "We now want to see if these entities appear in our grounding text. First, we place the grounding text into the general milieu of our kernel, so it can form background information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a06b342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "context[\"reference_context\"] = grounding_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fdd66f",
   "metadata": {},
   "source": [
    "With our grounding information in place, we can run the reference checking function (you didn't think that the pretty printing of the list of extracted entities was for _your_ benefit, did you?):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f048386c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Narrator's father\n",
      "- Daughter of Beaufort\n",
      "- Narrator's father's care\n"
     ]
    }
   ],
   "source": [
    "grounding_result = reference_check(extraction_result.result, context=context)\n",
    "\n",
    "print(grounding_result.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e132f2a",
   "metadata": {},
   "source": [
    "## Excision\n",
    "\n",
    "We can also try removing the extra entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0f152ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A respected public figure in Geneva was friends with a wealthy merchant named Beaufort, who fell into poverty and retreated to Lucerne with his daughter.\n",
      "This person searched for ten months before finding Beaufort, who was sick and unable to work. Beaufort died after several months, leaving his daughter an\n",
      "orphan and a beggar. This person took her under their care and eventually married her two years later.\n"
     ]
    }
   ],
   "source": [
    "context[\"target_entities\"] = grounding_result.result\n",
    "\n",
    "excision_result = entity_excision(summary_text, context=context)\n",
    "\n",
    "print(grounding_result.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef9a22f",
   "metadata": {},
   "source": [
    "## Using a Planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d51db6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.planning.basic_planner import BasicPlanner\n",
    "planner = BasicPlanner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "924d6b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_text = \"I like cars and trucks\"\n",
    "grounding_text = \"\"\"My sister and I both like aeroplanes and trucks. I am by birth a Genevese, and my family is one of the most distinguished of that republic. My ancestors had been for many years counsellors and syndics, and my father had filled several public situations with honour and reputation.\"\"\"\n",
    "\n",
    "target_topic = \"transportation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26047682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make a list of things related to transportation which are in the summary\n",
      "but which are not grounded in the original. Do not do anything else after extracting\n",
      "the list of things related to transportation.\n",
      "\n",
      "This is the summary text:\n",
      "\n",
      "[SUMMARY_TEXT]\n",
      "I like cars and trucks\n",
      "[/SUMMARY_TEXT]\n",
      "\n",
      "This was based on the following original text:\n",
      "\n",
      "[ORIGINAL_TEXT]\n",
      "My sister and I both like aeroplanes and trucks. I am by birth a Genevese, and my family is one of the most distinguished of that republic. My ancestors had been for many years counsellors and syndics, and my father had filled several public situations with honour and reputation.\n",
      "[/ORIGINAL_TEXT]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ask = f\"\"\"Make a list of things related to {target_topic} which are in the summary\n",
    "but which are not grounded in the original. Do not do anything else after extracting\n",
    "the list of things related to {target_topic}.\n",
    "\n",
    "This is the summary text:\n",
    "\n",
    "[SUMMARY_TEXT]\n",
    "{summary_text}\n",
    "[/SUMMARY_TEXT]\n",
    "\n",
    "This was based on the following original text:\n",
    "\n",
    "[ORIGINAL_TEXT]\n",
    "{grounding_text}\n",
    "[/ORIGINAL_TEXT]\n",
    "\"\"\"\n",
    "\n",
    "print(ask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f14ada",
   "metadata": {},
   "source": [
    "Write a new prompt for the planner, with the goal of getting better plans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc8f881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "# Task\n",
    "\n",
    "1. You are a planner for the Semantic Kernel.\n",
    "2. Your job is to create a properly formatted JSON plan step by step, to satisfy the goal given.\n",
    "3. Create a list of subtasks based off the [GOAL] provided.\n",
    "4. Each subtask must be from within the [AVAILABLE_FUNCTIONS] list. Do not use any functions that are not in the list.\n",
    "5. Base your decisions on which functions to use from the description and the name of the function.\n",
    "6. Sometimes, a function may take arguments. Provide them if necessary.\n",
    "7. The plan should be as short as possible.\n",
    "8. The plan does not have to use all of the [AVAILABLE_FUNCTIONS]\n",
    "9. Ensure that the plan you project is valid JSON. Remove new line characters if necessary\n",
    "\n",
    "Here are some examples:\n",
    "\n",
    "## Example 1\n",
    "\n",
    "[AVAILABLE_FUNCTIONS]\n",
    "EmailConnector.LookupContactEmail\n",
    "description: looks up the a contact and retrieves their email address\n",
    "args:\n",
    "- name: the name to look up\n",
    "\n",
    "WriterSkill.EmailTo\n",
    "description: email the input text to a recipient\n",
    "args:\n",
    "- input: the text to email\n",
    "- recipient: the recipient's email address. Multiple addresses may be included if separated by ';'.\n",
    "\n",
    "WriterSkill.Translate\n",
    "description: translate the input to another language\n",
    "args:\n",
    "- input: the text to translate\n",
    "- language: the language to translate to\n",
    "\n",
    "WriterSkill.Summarize\n",
    "description: summarize input text\n",
    "args:\n",
    "- input: the text to summarize\n",
    "\n",
    "FunSkill.Joke\n",
    "description: Generate a funny joke\n",
    "args:\n",
    "- input: the input to generate a joke about\n",
    "[/AVAILABLE_FUNCTIONS]\n",
    "\n",
    "[GOAL]\n",
    "Tell a joke about cars. Translate it to Spanish\n",
    "[/GOAL]\n",
    "\n",
    "[OUTPUT]\n",
    "    {\n",
    "        \"input\": \"cars\",\n",
    "        \"subtasks\": [\n",
    "            {\"function\": \"FunSkill.Joke\"},\n",
    "            {\"function\": \"WriterSkill.Translate\", \"args\": {\"language\": \"Spanish\"}}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "## Example 2\n",
    "\n",
    "[AVAILABLE_FUNCTIONS]\n",
    "WriterSkill.Brainstorm\n",
    "description: Brainstorm ideas\n",
    "args:\n",
    "- input: the input to brainstorm about\n",
    "\n",
    "WriterSkill.FollowStyle\n",
    "description: Rewrite a text in a given style\n",
    "args:\n",
    "- input: the original text\n",
    "- text_sample: A sample of text whose style should be used to rewrite the input\n",
    "\n",
    "WriterSkill.EmailTo\n",
    "description: Write an email to a recipient\n",
    "args:\n",
    "- input: the input to write about\n",
    "- recipient: the recipient's email address.\n",
    "\n",
    "WriterSkill.Translate\n",
    "description: translate the input to another language\n",
    "args:\n",
    "- input: the text to translate\n",
    "- language: the language to translate to\n",
    "[/AVAILABLE_FUNCTIONS]\n",
    "\n",
    "[GOAL]\n",
    "Tomorrow is Valentine's day. I need to come up with a few date ideas.\n",
    "She likes Edgar Allen Poe so write using his style.\n",
    "E-mail these ideas to my significant other. Translate it to French.\n",
    "\n",
    "The following is a sample text by Edgar Allen Poe:\n",
    "\n",
    "[SAMPLE_TEXT]\n",
    "Take thy beak from out my heart, and take thy form from off my door!\n",
    "Quoth the Raven, 'Nevermore.'\n",
    "[/SAMPLE_TEXT]\n",
    "[/GOAL]\n",
    "\n",
    "[OUTPUT]\n",
    "    {\n",
    "        \"input\": \"Valentine's Day Date Ideas\",\n",
    "        \"subtasks\": [\n",
    "            {\"function\": \"WriterSkill.Brainstorm\"},\n",
    "            {\"function\": \"WriterSkill.FollowStyle\", \"args\" : { \"text_sample\": \"Take thy beak from out my heart, and take thy form from off my door!\\nQuoth the Raven, 'Nevermore.'\"}},\n",
    "            {\"function\": \"WriterSkill.EmailTo\", \"args\": {\"recipient\": \"significant_other\"}},\n",
    "            {\"function\": \"WriterSkill.Translate\", \"args\": {\"language\": \"French\"}}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "## Example 3\n",
    "    \n",
    "[AVAILABLE_FUNCTIONS]\n",
    "TextSkill.Append\n",
    "description: append one text after another\n",
    "args:\n",
    "- input: the first text\n",
    "- second_text: the text to place after the first\n",
    "\n",
    "WriterSkill.Translate\n",
    "description: translate the input to another language\n",
    "args:\n",
    "- input: the text to translate\n",
    "- language: the language to translate to\n",
    "[/AVAILABLE_FUNCTIONS]\n",
    "\n",
    "[GOAL]\n",
    "I have two texts from the same original piece. The\n",
    "first needs to be translated into English, and then concatenated\n",
    "with the second.\n",
    "\n",
    "This is the first text:\n",
    "[TEXT_A]\n",
    "GALLIA est omnis divisa in partes tres, quarum unam incolunt Belgae,\n",
    "aliam Aquitani, tertiam qui ipsorum lingua Celtae, nostra Galli appellantur\n",
    "[/TEXT_A]\n",
    "\n",
    "This is the second text:\n",
    "[TEXT_B]\n",
    "All these differ from each other in language, customs and laws\n",
    "[/TEXT_B]\n",
    "[/GOAL]\n",
    "\n",
    "[OUTPUT]\n",
    "    {\n",
    "        \"input\": \"GALLIA est omnis divisa in partes tres, quarum unam incolunt Belgae,\\naliam Aquitani, tertiam qui ipsorum lingua Celtae, nostra Galli appellantur\",\n",
    "        \"subtasks\": [\n",
    "            {\"function\": \"WriterSkill.Translate\", \"args\": { \"language\": \"english\" }},\n",
    "            {\"function\": \"TextSkill.Append\", \"args\" : { \"second_text\": \"All these differ from each other in language, customs and laws\"}}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Task\n",
    "\n",
    "Produce an execution plan for the following goal, based on these functions:\n",
    "\n",
    "[AVAILABLE_FUNCTIONS]\n",
    "{{$available_functions}}\n",
    "[/AVAILABLE_FUNCTIONS]\n",
    "\n",
    "[GOAL]\n",
    "{{$goal}}\n",
    "[/GOAL]\n",
    "\n",
    "[OUTPUT]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45277db1",
   "metadata": {},
   "source": [
    "Now, generate the plan.\n",
    "In theory, only two skills should be used; extract the entities, and then reference check them.\n",
    "This might not :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f2e0c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"input\": \"My sister and I both like aeroplanes and trucks. I am by birth a Genevese, and my family is one of the most distinguished of that republic. My ancestors had been for many years counsellors and syndics, and my father had filled several public situations with honour and reputation.\",\n",
      "    \"subtasks\": [\n",
      "        {\"function\": \"SummarizeSkill.Summarize\"},\n",
      "        {\"function\": \"GroundingSkill.ExtractEntities\", \"args\": {\"topic\": \"transportation\"}},\n",
      "        {\"function\": \"GroundingSkill.ReferenceCheckEntities\", \"args\": {\"reference_context\": \"My sister and I both like aeroplanes and trucks.\"}},\n",
      "        {\"function\": \"GroundingSkill.ExciseEntities\", \"args\": {\"target_entities\": [entities returned by reference check]}}\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "my_plan = await planner.create_plan_async(ask, kernel, prompt=PROMPT)\n",
    "\n",
    "print(my_plan.generated_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e17e98",
   "metadata": {},
   "source": [
    "Run the plan and see what we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb855e84",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 7 column 84 (char 689)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m planner\u001b[38;5;241m.\u001b[39mexecute_plan_async(my_plan, kernel, debug_print\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "File \u001b[1;32mD:\\repos\\semantic-kernel\\python\\semantic_kernel\\planning\\basic_planner.py:190\u001b[0m, in \u001b[0;36mBasicPlanner.execute_plan_async\u001b[1;34m(self, plan, kernel, debug_print)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_plan_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, plan: Plan, kernel: Kernel, debug_print: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    186\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m    Given a plan, execute each of the functions within the plan\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;124;03m    from start to finish and output the result.\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m     generated_plan \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerated_plan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m     context \u001b[38;5;241m=\u001b[39m ContextVariables()\n\u001b[0;32m    193\u001b[0m     context[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m generated_plan[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\sk-311\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\sk-311\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\sk-311\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 7 column 84 (char 689)"
     ]
    }
   ],
   "source": [
    "results = await planner.execute_plan_async(my_plan, kernel, debug_print=True)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc771da",
   "metadata": {},
   "source": [
    "## A More Complicated Plan and new skills\n",
    "\n",
    "Now, let's ask for something more complicated.\n",
    "We can give the planner a longer text, ask it to summarise the text, then extract entities, cross check them, and remove any which shouldn't be there.\n",
    "However, there's a problem with doing this: how to pass the summary around.\n",
    "\n",
    "The planner we're using makes the output of each function into the input of the next. Other arguments can be passed in via the context, but these have to be known at the time the planner is invoked; they can't be previous outputs.\n",
    "This gives us a problem for the task described above; the summary has to be passed into both the 'extract entities' stage, and the 'excise entities' stage, but is itself the output of the 'summarise text' stage.\n",
    "For this, we're going to make use of variants of the previous skills, which will keep the summary in the output, and pass it through.\n",
    "\n",
    "Let's start by describing what we want to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41e3bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask2 = f\"\"\"\n",
    "Summarise the text between [TEXT] and [/TEXT]. Then make a list of entities related to {target_topic} in\n",
    "the summary. Check this list against the text given below, and make a list of the entities which are in the\n",
    "summary but not the original text. Take this list and rewrite the summary to remove those entities.\n",
    "\n",
    "This is the text to summarise:\n",
    "\n",
    "[TEXT]\n",
    "{grounding_text}\n",
    "[/TEXT]\n",
    "\"\"\"\n",
    "\n",
    "print(ask2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb20cf59",
   "metadata": {},
   "source": [
    "Now, create a new semantic kernel, and add skills to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41ac1f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_2 = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = True\n",
    "\n",
    "# Configure AI service used by the kernel\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel_2.add_text_completion_service(\"dv\", AzureTextCompletion(deployment, endpoint, api_key))\n",
    "else:\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "    kernel_2.add_text_completion_service(\"dv\", OpenAITextCompletion(\"text-davinci-003\", api_key, org_id))\n",
    "    \n",
    "# note: using skills from the samples folder\n",
    "skills_directory = \"../../skills\"\n",
    "\n",
    "# Note change in directory\n",
    "groundingSkill = kernel_2.import_semantic_skill_from_directory(skills_directory, \"Grounding2Skill\")\n",
    "summarize_skill = kernel_2.import_semantic_skill_from_directory(skills_directory, \"SummarizeSkill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a981a07b",
   "metadata": {},
   "source": [
    "### Separate Stages\n",
    "\n",
    "As before, let's go through the pipeline we want stage by stage, before trying to use the planner.\n",
    "\n",
    "First, a summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c99626e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "My sister and I both enjoy aeroplanes and trucks. I am from Geneva and my family is well-known and respected. My ancestors were counselors and syndics, and my father had held several public positions with distinction.\n"
     ]
    }
   ],
   "source": [
    "summary_result = summarize_skill['Summarize'](grounding_text).result\n",
    "\n",
    "print(summary_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c27f9a",
   "metadata": {},
   "source": [
    "Now we extract entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5fd4625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<entities>\n",
      "- My sister\n",
      "- Geneva\n",
      "- My family\n",
      "- My ancestors\n",
      "- Counselors\n",
      "- Syndics\n",
      "- My father\n",
      "</entities>\n",
      "\n",
      "<context>\n",
      "My sister and I both enjoy aeroplanes and trucks. I am from Geneva and my family is well-known and respected. My ancestors were counselors and syndics, and my father had held several public positions with distinction.\n",
      "</context>\n"
     ]
    }
   ],
   "source": [
    "context = kernel_2.create_new_context()\n",
    "context[\"grounding_context\"] = grounding_text\n",
    "context[\"topic\"] = \"people and places\"\n",
    "context[\"example_entities\"] = \"names of people, familial relationships and towns\"\n",
    "\n",
    "entity_extraction_result = groundingSkill['ExtractEntities'](summary_result, context=context).result\n",
    "\n",
    "print(entity_extraction_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488e2ee8",
   "metadata": {},
   "source": [
    "Note how we're repeating the summary, so we can pass it through. Now do the cross check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3dcab91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<ungrounded_entities>\n",
      "- Counselors\n",
      "- Syndics\n",
      "</ungrounded_entities>\n",
      "\n",
      "<context>\n",
      "My sister and I both enjoy aeroplanes and trucks. I am from Geneva and my family is well-known and respected. My ancestors were counselors and syndics, and my father had held several public positions with distinction.\n",
      "</context>\n"
     ]
    }
   ],
   "source": [
    "reference_check_result = groundingSkill['ReferenceCheckEntities'](entity_extraction_result, context=context).result\n",
    "\n",
    "print(reference_check_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaf87c3",
   "metadata": {},
   "source": [
    "Finally try to excise the ungrounded entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b69b1cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "My sister and I both enjoy aeroplanes and trucks. I am from Geneva and my family is well-known and respected. My ancestors had held several public positions with distinction.\n"
     ]
    }
   ],
   "source": [
    "excision_result = groundingSkill['ExciseEntities'](reference_check_result, context=context).result\n",
    "\n",
    "print(excision_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156724e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
